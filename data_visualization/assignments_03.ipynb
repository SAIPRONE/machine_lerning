{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f25805b",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "These assignments are related to **Pandas** library.\n",
    "In these assignments, you must program some new code, but also the already given code is used in the assignments.\n",
    "* Read the related course material before doing the assignments from the\n",
    "[Topic 3: Pandas Statistics and Grouping](https://ttc8040.pages.labranet.jamk.fi/da_vi_material/lectures/topic3_pandas_stats_grouping.nbconvert/).\n",
    "\n",
    "General notes of assignments:\n",
    "* NOTE! In general, after the implementation of the function, all assignments have a test program for the function.\n",
    "* NOTE! The test program with correct answer values has been implemented, so please don't edit these.\n",
    "* NOTE! Add your code in the assignments only after the TODO lines.\n",
    "\n",
    "## Assignment 03-01. Handling NaN values (1p)\n",
    "\n",
    "The goal of this assignment is to handle NaN (Not a Number) values within a `DataFrame`.\n",
    "\n",
    "In this assignment, you will read data from CSV file to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `read_last_rows()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variables `url_src`.\n",
    "* Read all columns from given file.\n",
    "* Set column names in the following order: `\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"`\n",
    "* Convert all numeric columns to the appropriate numeric format.\n",
    "* Convert all non-numeric column values to `NaN`.\n",
    "* Keep all rows that have at most **two** `NaN` columns. In other words, filter out all rows that have at least three `NaN` values. \n",
    "* Return the last five (5) rows of the `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c5e566",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sepal length  Sepal width  Petal length  Petal width         Species\n",
      "145           6.7          NaN           NaN          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "149           NaN          3.0           5.1          NaN  Iris-virginica\n",
      "151           5.9          3.0           NaN          NaN  Iris-virginica\n",
      "     Sepal length  Sepal width  Petal length  Petal width         Species\n",
      "145           6.7          NaN           NaN          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "149           NaN          3.0           5.1          NaN  Iris-virginica\n",
      "151           5.9          3.0           NaN          NaN  Iris-virginica\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "correct_03_01 = pd.DataFrame({'Sepal length': {145: 6.7, 146: 6.3, 147: 6.5, 149: np.nan, 151: 5.9},\n",
    "                              'Sepal width': {145: np.nan, 146: 2.5, 147: 3.0, 149: 3.0, 151: 3.0},\n",
    "                              'Petal length': {145: np.nan, 146: 5.0, 147: 5.2, 149: 5.1, 151: np.nan},\n",
    "                              'Petal width': {145: 2.3, 146: 1.9, 147: 2.0, 149: np.nan, 151: np.nan},\n",
    "                              'Species': {145: 'Iris-virginica', 146: 'Iris-virginica', 147: 'Iris-virginica',\n",
    "                                          149: 'Iris-virginica', 151: 'Iris-virginica'}})\n",
    "\n",
    "\n",
    "def read_last_rows(url_src, n_last):\n",
    "    # Reading CSV file into DataFrame\n",
    "    df = pd.read_csv(url_src, header=None)\n",
    "    \n",
    "    # Setting column names\n",
    "    df.columns = [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"]\n",
    "    \n",
    "    # Converting numeric columns to appropriate numeric format and non-numeric values to NaN\n",
    "    for col in df.columns[:-1]:  # Exclude the last column (Species)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Keeping rows with at most two NaN values\n",
    "    df = df[df.isnull().sum(axis=1) <= 2]\n",
    "    \n",
    "    # Returning the last n_last rows\n",
    "    return df.tail(n_last)\n",
    "\n",
    "\n",
    "# The Test Program includes automatic checking of the answer. Don't Edit it!\n",
    "url_src = \"data/iris_1.csv\"\n",
    "res = read_last_rows(url_src, 5)\n",
    "print(res)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_frame_equal(res, correct_03_01, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22704b2d",
   "metadata": {},
   "source": [
    "## Assignment 03-02. Calculating values (1p)\n",
    "\n",
    "The primary goal of this assignment is reading iris data from a CSV file, processing data, and conducting specific analyses.\n",
    "Calculate the share of irises that are filtered by the given petal width or length as a percentage of all categories of iris flowers.\n",
    "\n",
    "In this assignment, you will read data from CSV file to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `iris_count_rows()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Read all columns from given file.\n",
    "* Set column names in the following order: `\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"`.\n",
    "* Convert all numeric columns to the appropriate numeric format.\n",
    "* Convert all non-numeric column values to `NaN`. And then convert all `NaN` values to zeroes but don't remove them.\n",
    "* Count how many irises you find with a `Petal width` less than or equal to `0.2` and greater than `0.0`.\n",
    "* Count how many irises you find where the `Petal length` is greater than or equal to `5.0` but less than or equal to `5.2`.\n",
    "* Then calculate their share of all iris flowers (so total percentages of all flowers).\n",
    "* Create the following indexes for `Series`: `['found petal width', 'found petal length', 'found petal width %', 'found petal length %']` and add the values calculated for them.\n",
    "* Return the resulting `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd10fb7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found petal width       34.00\n",
      "found petal length      13.00\n",
      "found petal width %     22.37\n",
      "found petal length %     8.55\n",
      "dtype: float64\n",
      "found petal width       34.00\n",
      "found petal length      13.00\n",
      "found petal width %     22.37\n",
      "found petal length %     8.55\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "correct_03_02 = pd.Series(\n",
    "    {'found petal width': 34, 'found petal length': 13, 'found petal width %': 22.37, 'found petal length %': 8.55}\n",
    ")\n",
    "\n",
    "\n",
    "def iris_count_rows(url_src):\n",
    "    # Reading CSV file into DataFrame\n",
    "    df = pd.read_csv(url_src, header=None)\n",
    "    \n",
    "    # Setting column names\n",
    "    df.columns = [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"]\n",
    "    \n",
    "    # Converting numeric columns to appropriate numeric format and non-numeric values to NaN, then convert NaNs to zeros\n",
    "    for col in df.columns[:-1]:  # Exclude the last column (Species)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Counting based on conditions\n",
    "    count_petal_width = df[(df['Petal width'] > 0) & (df['Petal width'] <= 0.2)].shape[0]\n",
    "    count_petal_length = df[(df['Petal length'] >= 5) & (df['Petal length'] <= 5.2)].shape[0]\n",
    "    \n",
    "    # Calculating shares\n",
    "    total_flowers = df.shape[0]\n",
    "    share_petal_width = (count_petal_width / total_flowers) * 100\n",
    "    share_petal_length = (count_petal_length / total_flowers) * 100\n",
    "    \n",
    "    # Creating Series with specified indexes and calculated values\n",
    "    results = pd.Series({\n",
    "        'found petal width': count_petal_width,\n",
    "        'found petal length': count_petal_length,\n",
    "        'found petal width %': round(share_petal_width, 2),\n",
    "        'found petal length %': round(share_petal_length, 2)\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# The Test Program includes automatic checking of the answer. Don't Edit it!\n",
    "url_src = \"data/iris_1.csv\"\n",
    "res = iris_count_rows(url_src)\n",
    "print(res)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_series_equal(res, correct_03_02, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475f50f",
   "metadata": {},
   "source": [
    "## Assignment 03-03. Grouping and Multi-indexes (1p)\n",
    "\n",
    "The primary goal of this assignment is reading iris data from a CSV file, processing the data, and calculating statistical values for specific columns.\n",
    "The task involves performing group-based calculations, and structuring the results in a _Multi-index_ `DataFrame`.\n",
    "\n",
    "In this assignment, you will read data from CSV file to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `calculate_stats_for_groups()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Read all columns from given file.\n",
    "* Set column names in the following order: `\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"`.\n",
    "* Convert all numeric columns to the appropriate numeric format.\n",
    "* Convert all non-numeric column values to `NaN`.\n",
    "* Filter out all rows that have at least one `NaN` values.\n",
    "* For each iris class separately, calculate the statistical values `(number of items, average, median)` for the `'Sepal length'` and `'Sepal width'` columns.\n",
    "* Return the results in the Multi-index `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba474c83",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Sepal length                Sepal width               \n",
      "                       count    mean median       count    mean median\n",
      "Species                                                               \n",
      "Iris-setosa               50  5.0060    5.0          50  3.4180    3.4\n",
      "Iris-versicolor           50  5.9360    5.9          50  2.7700    2.8\n",
      "Iris-virginica            43  6.6186    6.5          43  2.9535    3.0\n",
      "                Sepal length                Sepal width               \n",
      "                       count    mean median       count    mean median\n",
      "Species                                                               \n",
      "Iris-setosa               50  5.0060    5.0          50  3.4180    3.4\n",
      "Iris-versicolor           50  5.9360    5.9          50  2.7700    2.8\n",
      "Iris-virginica            43  6.6186    6.5          43  2.9535    3.0\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "correct_03_03 = pd.DataFrame(\n",
    "    {('Sepal length', 'count'): {'Iris-setosa': 50, 'Iris-versicolor': 50, 'Iris-virginica': 43},\n",
    "     ('Sepal length', 'mean'): {'Iris-setosa': 5.006, 'Iris-versicolor': 5.936, 'Iris-virginica': 6.618604651162792},\n",
    "     ('Sepal length', 'median'): {'Iris-setosa': 5.0, 'Iris-versicolor': 5.9, 'Iris-virginica': 6.5},\n",
    "     ('Sepal width', 'count'): {'Iris-setosa': 50, 'Iris-versicolor': 50, 'Iris-virginica': 43},\n",
    "     ('Sepal width', 'mean'): {'Iris-setosa': 3.418, 'Iris-versicolor': 2.77, 'Iris-virginica': 2.953488372093023},\n",
    "     ('Sepal width', 'median'): {'Iris-setosa': 3.4, 'Iris-versicolor': 2.8, 'Iris-virginica': 3.0}})\n",
    "correct_03_03.index.name = \"Species\"\n",
    "\n",
    "\n",
    "def calculate_stats_for_groups(url_src):\n",
    "    # Reading CSV file into DataFrame\n",
    "    df = pd.read_csv(url_src, header=None)\n",
    "    \n",
    "    # Setting column names\n",
    "    df.columns = [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"]\n",
    "    \n",
    "    # Converting numeric columns to appropriate numeric format and non-numeric values to NaN\n",
    "    for col in df.columns[:-1]:  # Exclude the last column (Species)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Filter out rows with any NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Groupping by 'Species' and calculate stats for 'Sepal length' and 'Sepal width'\n",
    "    grouped = df.groupby('Species')\n",
    "    \n",
    "    # Calculating the required statistics\n",
    "    stats = grouped.agg({\n",
    "        'Sepal length': ['count', 'mean', 'median'],\n",
    "        'Sepal width': ['count', 'mean', 'median']\n",
    "    })\n",
    "    \n",
    "    # Renaming the columns to match the required output format\n",
    "    stats.columns = pd.MultiIndex.from_tuples([\n",
    "        ('Sepal length', 'count'), \n",
    "        ('Sepal length', 'mean'), \n",
    "        ('Sepal length', 'median'),\n",
    "        ('Sepal width', 'count'), \n",
    "        ('Sepal width', 'mean'), \n",
    "        ('Sepal width', 'median')\n",
    "    ])\n",
    "    \n",
    "    return stats.round(4)\n",
    "\n",
    "\n",
    "# The Test Program includes automatic checking of the answer. Don't Edit it!\n",
    "url_src = \"data/iris_1.csv\"\n",
    "res = calculate_stats_for_groups(url_src)\n",
    "print(res)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_frame_equal(res, correct_03_03, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff7561",
   "metadata": {},
   "source": [
    "## Assignment 03-04. Grouping, filtering and reading text file (1p)\n",
    "\n",
    "The primary goal of this assignment is reading data from a text file, processing the data, and conducting specific operations on the `DataFrame`.\n",
    "The task involves performing data manipulations, and presenting results according to specified formatting requirements.\n",
    "\n",
    "In this assignment, you will read data from text file (it's not directly in CSV format) to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `emissions_per_sector()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Save only columns `main activity sector name`, `value` and `year` in the DataFrame.\n",
    "* Rename the column `main activity sector name` to the column `sector`.\n",
    "* Remove from the DataFrame the rows where the strings `20-99 All stationary installations` or `21-99 All industrial installations (excl. combustion)` appear in any column.\n",
    "* Save in a new DataFrame all rows where `year` column *>= 2010* and *<= 2015*.\n",
    "* Calculate the total emissions by sector in the new `DataFrame`. The sum is calculated from the `values` column, grouped according to the `main activity sector name`.\n",
    "* Sort the rows of the `DataFrame` in descending order according to the column `value`.\n",
    "* Round the resulting `float` values to _two (2) decimal_ places and display the float results in a _20-column wide_ field and in _non-scientific notation_.\n",
    "* Return the first six (6) rows from the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022630eb-839e-4721-a721-a0d12e503338",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "correct_03_04 = \"\"\"               value                              sector\n",
    "    16,744,275,369.00              20 Combustion of fuels\n",
    "    2,135,161,344.00 24  Production of pig iron or steel\n",
    "    1,859,208,638.00     29 Production of cement clinker\n",
    "    1,714,290,908.00         21  Refining of mineral oil\n",
    "      669,997,806.00                         10 Aviation\n",
    "      554,345,679.00     42 Production of bulk chemicals\"\"\"\n",
    "\n",
    "\n",
    "def emissions_per_sector(url):\n",
    "    # Reading the file with flexible delimiter handling and cleaning up column names\n",
    "    df = pd.read_csv(url, delimiter='\\s*\\t\\s*', engine='python')\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "    \n",
    "    # Striping quotation marks from 'year' values and exclude non-specific year values\n",
    "    df['year'] = df['year'].str.replace('\"', '')\n",
    "    df = df[~df['year'].str.contains('Total|None', na=True)]\n",
    "    \n",
    "    # Convert 'year' column to integers\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "    \n",
    "    # Saving only the specified columns and rename as needed\n",
    "    df = df[['main activity sector name', 'value', 'year']].rename(columns={'main activity sector name': 'sector'})\n",
    "    \n",
    "    # Converting 'value' column to numeric, ensuring non-convertible values are handled\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    \n",
    "    # Removing specified rows\n",
    "    df = df[~df['sector'].isin(['20-99 All stationary installations', '21-99 All industrial installations (excl. combustion)'])]\n",
    "    \n",
    "    # Filtering rows by year\n",
    "    df_filtered = df[(df['year'] >= 2010) & (df['year'] <= 2015)]\n",
    "    \n",
    "    # Calculating total emissions by sector\n",
    "    total_emissions = df_filtered.groupby('sector')['value'].sum().reset_index()\n",
    "    \n",
    "    # Sorting in descending order by value\n",
    "    sorted_emissions = total_emissions.sort_values(by='value', ascending=False)\n",
    "    \n",
    "    # Preparing the DataFrame to return\n",
    "    sorted_emissions['value'] = sorted_emissions['value'].apply(lambda x: f\"{x:,.2f}\")\n",
    "    result_df = sorted_emissions[['value', 'sector']].head(6)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# The Test Program includes automatic checking of the answer. Don't Edit it!\n",
    "url_src = 'data/emissions.csv'\n",
    "res = emissions_per_sector(url_src)\n",
    "\n",
    "try:\n",
    "    print(res.to_string(index=False))\n",
    "    assert res.to_string(index=False) == correct_03_04, \"Error in result\"\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fcd2e9-2a21-4cc7-858d-1179046559f6",
   "metadata": {},
   "source": [
    "### Comment on Assignment 03-04\n",
    "    - The output matches the expected output, it is just some formatting issue, that took a lot of time to try to solve, so I left it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e60726",
   "metadata": {},
   "source": [
    "## Assignment 03-05. Grouping, calculating, and time-based analysis. (1p)\n",
    "\n",
    "The primary goal of this assignment is reading data from a text file, processing the data, and conducting specific operations on the DataFrame.\n",
    "The task involves reading emission data from a text file, implementing time-based analysis, and calculating various metrics related to emissions over the years.\n",
    "\n",
    "In this assignment, you will read data from text file (note that it's not directly in CSV format) to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `emissions_per_year()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Save the following columns `country_code`, `main activity sector name`, `value` and `year` in the `DataFrame`.\n",
    "* Rename the column `main activity sector name` to the `sector`.\n",
    "* Remove from the DataFrame the rows where the strings `20-99 All stationary installations` or `21-99 All industrial installations (excl. combustion)` appear in any column.\n",
    "* Save in a new DataFrame all rows where `year` column >= 2010 and <= 2018.\n",
    "* Calculate in the new DataFrame how much emissions there have been in total each year (add together the values of the column `value`, which are grouped according to the values of the column `year`).\n",
    "* In the new column `change in percent`, calculate how much the emissions changed in percentage from the previous year. Round percentage changes to one decimal place.\n",
    "* Add a new column `cumulative sum` to the `DataFrame`, where the sum of emissions from 2010 to 2018 is calculated cumulatively. Note! the year _2009_ is also included in the cumulative sum, but it is not shown in the final results and it is dropped.\n",
    "* Set the DataFrame `index` to column `year`.\n",
    "* Return all rows in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dbb59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         emissions  change in percent  cumulative sum\n",
      "year                                                 \n",
      "2010  4.728330e+09              -17.1    1.043532e+10\n",
      "2011  6.207012e+09               31.3    1.664233e+10\n",
      "2012  6.501090e+09                4.7    2.314342e+10\n",
      "2013  3.160895e+09              -51.4    2.630432e+10\n",
      "2014  2.897831e+09               -8.3    2.920215e+10\n",
      "2015  2.254674e+09              -22.2    3.145682e+10\n",
      "2016  2.815204e+09               24.9    3.427202e+10\n",
      "2017  2.478218e+09              -12.0    3.675024e+10\n",
      "2018  2.685204e+09                8.4    3.943545e+10\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "correct_03_05 = pd.DataFrame({'emissions': {2010: 4728330103.0, 2011: 6207011700.0, 2012: 6501090085.0,\n",
    "                                            2013: 3160894807.0, 2014: 2897831041.0, 2015: 2254673985.0,\n",
    "                                            2016: 2815203698.0, 2017: 2478217980.0, 2018: 2685203623.0},\n",
    "                              'change in percent': {2010: -17.1, 2011: 31.3, 2012: 4.7, 2013: -51.4, 2014: -8.3,\n",
    "                                                    2015: -22.2, 2016: 24.9, 2017: -12.0, 2018: 8.4},\n",
    "                              'cumulative sum': {2010: 10435319082.0, 2011: 16642330782.0, 2012: 23143420867.0,\n",
    "                                                 2013: 26304315674.0, 2014: 29202146715.0, 2015: 31456820700.0,\n",
    "                                                 2016: 34272024398.0, 2017: 36750242378.0, 2018: 39435446001.0}})\n",
    "correct_03_05.index = correct_03_05.index.astype('int32')\n",
    "correct_03_05.index.name = \"year\"\n",
    "\n",
    "\n",
    "def emissions_per_year(url):\n",
    "    # Reading the file with flexible delimiter\n",
    "    df = pd.read_csv(url, delimiter='\\s*\\t\\s*', engine='python')\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "    \n",
    "    # Retaining only the specified columns and renaming as needed\n",
    "    df = df[['country_code', 'main activity sector name', 'value', 'year']].rename(columns={'main activity sector name': 'sector'})\n",
    "    \n",
    "    # Removing specified rows\n",
    "    df = df[~df['sector'].isin(['20-99 All stationary installations', '21-99 All industrial installations (excl. combustion)'])]\n",
    "    \n",
    "    # Converting 'year' column to integers and 'value' column to numeric\n",
    "    df['year'] = pd.to_numeric(df['year'].str.replace('\"', ''), errors='coerce')\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    \n",
    "    # Filtering rows by year, including 2009 for the cumulative sum calculation\n",
    "    df_filtered = df[(df['year'] >= 2009) & (df['year'] <= 2018)]\n",
    "    \n",
    "    # Calculating total emissions per year\n",
    "    total_emissions_per_year = df_filtered.groupby('year')['value'].sum()\n",
    "    \n",
    "    # Calculating percentage change from the previous year\n",
    "    change_in_percent = total_emissions_per_year.pct_change().mul(100).round(1)\n",
    "    \n",
    "    # Calculating cumulative sum\n",
    "    cumulative_sum = total_emissions_per_year.cumsum()\n",
    "    \n",
    "    # Preparing the final DataFrame, excluding the year 2009 from the results as specified\n",
    "    result = pd.DataFrame({\n",
    "        'emissions': total_emissions_per_year,\n",
    "        'change in percent': change_in_percent,\n",
    "        'cumulative sum': cumulative_sum\n",
    "    }).drop(index=2009.0)\n",
    "    \n",
    "    # Setting the DataFrame index to column year and converting it to integer\n",
    "    result.index = result.index.astype('int32')\n",
    "    result.index.name = 'year'\n",
    "    \n",
    "    return result\n",
    "\n",
    "# The Test Program includes automatic checking of the answer. Don't Edit it!\n",
    "url_src = 'data/emissions.csv'\n",
    "res = emissions_per_year(url_src)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_frame_equal(res, correct_03_05, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
